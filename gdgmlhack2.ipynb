{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":127593,"databundleVersionId":15603876,"sourceType":"competition"},{"sourceId":745469,"sourceType":"modelInstanceVersion","modelInstanceId":569122,"modelId":581444}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ==========================================\n# 1. SETUP & IMPORTS\n# ==========================================\n!pip install -q segmentation_models_pytorch gdown\n\nimport os\nimport cv2\nimport glob\nimport torch\nimport gdown\nimport numpy as np\nimport pandas as pd\nimport torch.nn.functional as F\nimport segmentation_models_pytorch as smp\n\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom dataclasses import dataclass\n\n# ==========================================\n# 2. CONFIGURATION\n# ==========================================\n@dataclass\nclass Cfg:\n    # Paths\n    TEST_DIR: str = \"/kaggle/input/terra-seg-rugged-terrain-segmentation/offroad-seg-kaggle/test_images_padded\"\n    WORK_DIR: str = \"/kaggle/working\"\n    MODEL_DIR: str = os.path.join(WORK_DIR, \"weights\")\n    MASK_OUT_DIR: str = os.path.join(WORK_DIR, \"binary_masks\")\n    SUBMISSION_PATH: str = os.path.join(WORK_DIR, \"submission.csv\")\n    \n    # Drive Link\n    DRIVE_URL: str = \"https://drive.google.com/drive/folders/1kApmkblFvkT1kRtbe23zMnnxl02pATmB?usp=sharing\"\n    \n    # Model Configs\n    CKPT_DEEPLAB: str = \"deeplab.pth\"\n    CKPT_HRNET: str = \"best_offseg_hrnet_unet.pth\"\n    \n    # Inference Parameters\n    ORIG_SIZE: tuple = (540, 960)  # (H, W)\n    MODEL_SIZE: tuple = (544, 960) # (H, W)\n    THRESHOLD: float = 0.48\n    DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    BATCH_SIZE: int = 1\n    NUM_WORKERS: int = 2\n\n# Create directories\nos.makedirs(Cfg.MODEL_DIR, exist_ok=True)\nos.makedirs(Cfg.MASK_OUT_DIR, exist_ok=True)\n\n# ==========================================\n# 3. UTILITIES\n# ==========================================\ndef download_weights(cfg: Cfg):\n    \"\"\"Downloads model weights from Google Drive using gdown.\"\"\"\n    print(f\" Downloading weights to {cfg.MODEL_DIR}...\")\n    gdown.download_folder(url=cfg.DRIVE_URL, output=cfg.MODEL_DIR, quiet=False, use_cookies=False)\n    \n    # Verify files\n    required = [cfg.CKPT_DEEPLAB, cfg.CKPT_HRNET]\n    files = os.listdir(cfg.MODEL_DIR)\n    for f in required:\n        if f not in files:\n            raise FileNotFoundError(f\" Missing file: {f}\")\n    print(\" Download complete.\")\n\ndef rle_encode(mask: np.ndarray) -> str:\n    \"\"\"Run-Length Encode a binary mask.\"\"\"\n    pixels = mask.flatten(order=\"F\")\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return \" \".join(map(str, runs))\n\ndef load_model(arch: str, path: str, device: str):\n    \"\"\"Factory function to load and freeze models.\"\"\"\n    path = os.path.join(Cfg.MODEL_DIR, path)\n    \n    if arch == \"deeplab\":\n        model = smp.DeepLabV3Plus(\"resnet34\", encoder_weights=None, classes=1)\n        state_dict = torch.load(path, map_location=device)[\"model_state_dict\"]\n    elif arch == \"hrnet\":\n        model = smp.Unet(\n            encoder_name=\"tu-hrnet_w32\", \n            encoder_weights=None, \n            classes=1, \n            decoder_attention_type=\"scse\"\n        )\n        state_dict = torch.load(path, map_location=device)\n    else:\n        raise ValueError(f\"Unknown architecture: {arch}\")\n\n    model.load_state_dict(state_dict)\n    model.to(device)\n    model.eval()\n    \n    # Freeze parameters\n    for param in model.parameters():\n        param.requires_grad = False\n        \n    return model\n\n# ==========================================\n# 4. DATASET PIPELINE\n# ==========================================\nclass TerrainDataset(Dataset):\n    def __init__(self, root_dir, model_size):\n        self.image_paths = sorted(glob.glob(os.path.join(root_dir, \"*.png\")))\n        self.model_h, self.model_w = model_size\n        \n        # Define transforms\n        self.norm = transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])\n        self.to_tensor = transforms.ToTensor()\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        path = self.image_paths[idx]\n        img_id = os.path.splitext(os.path.basename(path))[0]\n        \n        # Load Image\n        img_pil = Image.open(path).convert(\"RGB\")\n        \n        # Branch 1: Padding for DeepLab\n        # Matches original logic: pad (left, top, right, bottom) -> (0, 2, 0, 2)\n        img_pad_pil = transforms.functional.pad(img_pil, (0, 2, 0, 2))\n        img_pad_tensor = self.norm(self.to_tensor(img_pad_pil))\n        \n        # Branch 2: Resize for HRNet\n        img_resize_pil = img_pil.resize((self.model_w, self.model_h), Image.BILINEAR)\n        img_resize_tensor = self.norm(self.to_tensor(img_resize_pil))\n        \n        return {\n            \"image_id\": img_id,\n            \"path\": path,\n            \"input_pad\": img_pad_tensor,     # For DeepLab\n            \"input_resize\": img_resize_tensor # For HRNet\n        }\n\n# ==========================================\n# 5. MAIN INFERENCE LOOP\n# ==========================================\ndef run_inference():\n    # 1. Download Weights\n    download_weights(Cfg)\n    \n    # 2. Load Models\n    print(\" Loading models...\")\n    net_deeplab = load_model(\"deeplab\", Cfg.CKPT_DEEPLAB, Cfg.DEVICE)\n    net_hrnet = load_model(\"hrnet\", Cfg.CKPT_HRNET, Cfg.DEVICE)\n    \n    # 3. Prepare Data\n    if not os.path.exists(Cfg.TEST_DIR):\n        print(f\" Test directory not found: {Cfg.TEST_DIR}\")\n        return\n\n    dataset = TerrainDataset(Cfg.TEST_DIR, Cfg.MODEL_SIZE)\n    loader = DataLoader(dataset, batch_size=Cfg.BATCH_SIZE, shuffle=False, num_workers=Cfg.NUM_WORKERS)\n    print(f\" Found {len(dataset)} images.\")\n\n    results = []\n    \n    print(\" Starting inference...\")\n    with torch.no_grad():\n        for batch in tqdm(loader):\n            img_ids = batch[\"image_id\"]\n            paths = batch[\"path\"]\n            \n            # Move inputs to device\n            x_pad = batch[\"input_pad\"].to(Cfg.DEVICE)\n            x_resize = batch[\"input_resize\"].to(Cfg.DEVICE)\n            \n            # --- Forward Pass ---\n            out_deeplab = net_deeplab(x_pad)\n            out_hrnet = net_hrnet(x_resize)\n            \n            # --- Post-Process ---\n            prob_deeplab = torch.sigmoid(out_deeplab)\n            prob_hrnet = torch.sigmoid(out_hrnet)\n            \n            # Iterate through batch (even if size is 1)\n            for i in range(len(img_ids)):\n                # Interpolate to original size\n                # Note: Unsqueeze adds batch/channel dims required for interpolate\n                p_dl = F.interpolate(\n                    prob_deeplab[i].unsqueeze(0), size=Cfg.ORIG_SIZE, mode='bilinear', align_corners=False\n                ).squeeze().cpu().numpy()\n                \n                p_hr = F.interpolate(\n                    prob_hrnet[i].unsqueeze(0), size=Cfg.ORIG_SIZE, mode='bilinear', align_corners=False\n                ).squeeze().cpu().numpy()\n                \n                # Weighted Ensemble\n                ensemble_prob = (0.52 * p_hr) + (0.48 * p_dl)\n                mask = (ensemble_prob > Cfg.THRESHOLD).astype(np.uint8)\n                \n                # Save RLE\n                results.append({\n                    \"image_id\": img_ids[i],\n                    \"encoded_pixels\": rle_encode(mask)\n                })\n                \n                # Save PNG\n                cv2.imwrite(\n                    os.path.join(Cfg.MASK_OUT_DIR, os.path.basename(paths[i])),\n                    mask * 255\n                )\n\n    # 4. Save Submission\n    if results:\n        df = pd.DataFrame(results)\n        df.to_csv(Cfg.SUBMISSION_PATH, index=False)\n        print(f\"\\n Success! Submission saved to: {Cfg.SUBMISSION_PATH}\")\n        print(f\" Masks saved to: {Cfg.MASK_OUT_DIR}\")\n    else:\n        print(\" No predictions generated.\")\n\nif __name__ == \"__main__\":\n    run_inference()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-09T15:53:09.742885Z","iopub.execute_input":"2026-02-09T15:53:09.743208Z","iopub.status.idle":"2026-02-09T15:55:47.453409Z","shell.execute_reply.started":"2026-02-09T15:53:09.743182Z","shell.execute_reply":"2026-02-09T15:55:47.452413Z"}},"outputs":[{"name":"stdout","text":" Downloading weights to /kaggle/working/weights...\n","output_type":"stream"},{"name":"stderr","text":"Retrieving folder contents\n","output_type":"stream"},{"name":"stdout","text":"Processing file 1PlPTGIruNOI6U6jSVzCMMo5ARNJvhGS4 best_offseg_hrnet_unet.pth\nProcessing file 1aAnR3fwK8e6Nc7AK7R6LPHi2buHnNN__ deeplab.pth\n","output_type":"stream"},{"name":"stderr","text":"Retrieving folder contents completed\nBuilding directory structure\nBuilding directory structure completed\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1PlPTGIruNOI6U6jSVzCMMo5ARNJvhGS4\nFrom (redirected): https://drive.google.com/uc?id=1PlPTGIruNOI6U6jSVzCMMo5ARNJvhGS4&confirm=t&uuid=b032c2f3-88a4-4969-8568-5ef7abf49b81\nTo: /kaggle/working/weights/best_offseg_hrnet_unet.pth\n100%|██████████| 146M/146M [00:00<00:00, 161MB/s]  \nDownloading...\nFrom (original): https://drive.google.com/uc?id=1aAnR3fwK8e6Nc7AK7R6LPHi2buHnNN__\nFrom (redirected): https://drive.google.com/uc?id=1aAnR3fwK8e6Nc7AK7R6LPHi2buHnNN__&confirm=t&uuid=28a49eb7-3131-410c-b76f-743690d44018\nTo: /kaggle/working/weights/deeplab.pth\n100%|██████████| 270M/270M [00:03<00:00, 77.7MB/s] \nDownload completed\n","output_type":"stream"},{"name":"stdout","text":" Download complete.\n Loading models...\n Found 1002 images.\n Starting inference...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1002 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a846afcac5d9461099ea4ccc3e38b805"}},"metadata":{}},{"name":"stdout","text":"\n Success! Submission saved to: /kaggle/working/submission.csv\n Masks saved to: /kaggle/working/binary_masks\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}